{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naru289/Assignment-37/blob/main/SimCLR(Ungraded).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrnlrAtZKJni"
      },
      "source": [
        "SimCLR is a framework for constrastive learning of visual representations by maximizing agreement between differently augmented views of the same data example via a constrastive loss in the latent space.\n",
        "\n",
        "These visual representations are vectors on which linear classifiers can be trained to solve problems like image classification. We know that we can learn these visual representations by training deep learning models like ResNet on labeled datasets like ImageNet.\n",
        "\n",
        "\n",
        "This notebook contains a PyTorch implementation of the paper [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) by chen etal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adao81K-MFFF"
      },
      "source": [
        "### Importing the required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH7dH-IxQ_Wj"
      },
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as tfs\n",
        "from torchvision.datasets import *\n",
        "from torchvision.models import *\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHvJgQiiMI75"
      },
      "source": [
        "### Define the Transformations\n",
        "\n",
        "**Data augmentation module:** This module transforms any given data example stochastically generating two correlated views of the same example, denoted by $x_i$ and $x_j$. Here the authors used three simple augmentations: random cropping followed by reseizing to the original size, random color distortions, and random Gaussian blur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD8zN_jfRtTg"
      },
      "source": [
        "tf_tr = tfs.Compose([\n",
        "    tfs.RandomResizedCrop(32),\n",
        "    tfs.RandomHorizontalFlip(),\n",
        "    tfs.ColorJitter(0.5, 0.5, 0.5, 0.5),\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                  std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tf_de = tfs.Compose([\n",
        "    tfs.Resize(32),\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                  std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "tf_te = tfs.Compose([\n",
        "    tfs.Resize(32),\n",
        "    tfs.ToTensor(),\n",
        "    tfs.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                  std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLU78QKPMNY2"
      },
      "source": [
        "### Loading the CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2rWS3nTRwXM"
      },
      "source": [
        "class CustomCIFAR10(CIFAR10):\n",
        "    def __init__(self, **kwds):\n",
        "        super().__init__(**kwds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if not self.train:\n",
        "            return super().__getitem__(idx)\n",
        "\n",
        "        img = self.data[idx]\n",
        "        img = Image.fromarray(img).convert('RGB')\n",
        "        imgs = [self.transform(img), self.transform(img)]\n",
        "        return torch.stack(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeRjBHiJR0ML"
      },
      "source": [
        "# Download the dataset and apply the transformations\n",
        "ds_tr = CustomCIFAR10(root='data', train=True, transform=tf_tr, download=True)\n",
        "ds_de = CIFAR10(root='data', train=True, transform=tf_de, download=True)\n",
        "ds_te = CIFAR10(root='data', train=False, transform=tf_te, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JAGj7QrQ8FW"
      },
      "source": [
        "**Batch Size:** The authors experimented for a batch size N ranging from 256 to 8192. For a batch size of 8192 gives 16382 negative examples per positive pair from both augmentation views. Given the fact that SGD/Momentum doesnâ€™t tend to work well beyond a given batch size, the authors used LARS optimizer for all batch sizes. With 128 TPU v3 cores, training a ResNet-50 with a batch size of 4096 for 100 epochs takes ~1.5 hours.\n",
        "\n",
        "You can also increase the batch size to 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5uHG6V1R0Hx"
      },
      "source": [
        "# Load the dataset using dataloader\n",
        "dl_tr = DataLoader(ds_tr, batch_size=128, shuffle=True)\n",
        "dl_de = DataLoader(ds_de, batch_size=128, shuffle=True)\n",
        "dl_te = DataLoader(ds_te, batch_size=128, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_XidLBGMqcs"
      },
      "source": [
        "### Loading the ResNet50 Model\n",
        "\n",
        "**Base Encoder**: ResNet-50 is used as the base neural network encoder for extracting representation vectors from the augmented data examples. The output of the last average pooling layer used for extracting representations.\n",
        "\n",
        "Projection Head: A small neural network, MLP with one hidden layer, is used to map the representations from the base encoder to 128-dimensional latent space where contrastive loss is applied. ReLU is the activation function used in this projection head."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOz0y8Y8R0DZ"
      },
      "source": [
        "model = resnet50(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
        "model.maxpool = nn.Identity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWP0iDZ_Rz-7"
      },
      "source": [
        "ch = model.fc.in_features\n",
        "model.fc = nn.Sequential(nn.Linear(ch, ch),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Linear(ch, ch))\n",
        "model.to(device)\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jPON6hFNM_y"
      },
      "source": [
        "### Define the Contrastive loss Function\n",
        "\n",
        "**Contrastive Loss Function:** Given a set of examples including a positive pair of examples ($x_i$ and $x_j$), the contrastive prediction task aims to identify $x_j$ in the given set for a given $x_i$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC0KeifaRz5L"
      },
      "source": [
        "#  For comparing the representations produced by the projection head, we use cosine similarity which is defined as below\n",
        "def pair_cosine_similarity(x, eps=1e-8):\n",
        "    n = x.norm(p=2, dim=1, keepdim=True)\n",
        "    return (x @ x.t()) / (n * n.t()).clamp(min=eps)\n",
        "\n",
        "def nt_xent(x, t=0.5):\n",
        "    x = pair_cosine_similarity(x)\n",
        "    x = torch.exp(x / t)\n",
        "    idx = torch.arange(x.size()[0])\n",
        "    # Put positive pairs on the diagonal\n",
        "    idx[::2] += 1\n",
        "    idx[1::2] -= 1\n",
        "    x = x[idx]\n",
        "    # subtract the similarity of 1 from the numerator\n",
        "    x = x.diag() / (x.sum(0) - torch.exp(torch.tensor(1 / t)))\n",
        "    return -torch.log(x.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrJFZf2DRz1E"
      },
      "source": [
        "# Defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c1pyFN5UxkX"
      },
      "source": [
        " import torch\n",
        " torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxNvIBt9SzVl"
      },
      "source": [
        "### Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoint"
      ],
      "metadata": {
        "id": "MD5t970bGyXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCSzYAGDRzwD"
      },
      "source": [
        "model.train()\n",
        "PATH = '/content/checkpoint'\n",
        "for i in range(20): # Change the range number to train for 100 epochs\n",
        "    c, s = 0, 0\n",
        "    pBar = tqdm(dl_tr)\n",
        "    for data in pBar:\n",
        "        d = data.size()\n",
        "        x = data.view(d[0]*2, d[2], d[3], d[4]).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        p = model(x)\n",
        "        loss = nt_xent(p)\n",
        "        s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "        c += len(p)\n",
        "        pBar.set_description('Train: '+str(round(float(s),3)))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i+1) % 10 == 0:\n",
        "            torch.save(model.state_dict(),PATH+'cifar10-rn50-mlp-b256-t0.5-e'+str(i+1)+'.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZharOQmRzqY"
      },
      "source": [
        "# Freeze the sequential model parameter and train only the classifier by changing the number of classes to 10 for cifar 10\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ImJhE1xRzjM"
      },
      "source": [
        "model.fc = nn.Linear(ch, len(ds_de.classes))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnCSPtERzZ2"
      },
      "source": [
        "# Initialize the optimizer with a different learning rate\n",
        "optimizer = Adam(model.parameters(), lr=0.003)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my5nABrZST47"
      },
      "source": [
        "# Train the model again and do the forwhard pass and update the weights\n",
        "model.train()\n",
        "for i in range(5):\n",
        "    c, s = 0, 0\n",
        "    pBar = tqdm(dl_de)\n",
        "    for data in pBar:\n",
        "        x, y = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        p = model(x)\n",
        "        loss = criterion(p, y)\n",
        "        s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "        c += len(p)\n",
        "        pBar.set_description('Train: '+str(round(float(s),3)))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eblH4zrPis_k"
      },
      "source": [
        "optimizer = Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8QLPRNXSTwh"
      },
      "source": [
        "# Training the model with a learning rate of 0.0001\n",
        "model.train()\n",
        "for i in range(5):\n",
        "    c, s = 0, 0\n",
        "    pBar = tqdm(dl_de)\n",
        "    for data in pBar:\n",
        "        x, y = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        p = model(x)\n",
        "        loss = criterion(p, y)\n",
        "        s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "        c += len(p)\n",
        "        pBar.set_description('Train: '+str(round(float(s),3)))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N4Sw-6QTVYx"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LywF4_0ISTsf"
      },
      "source": [
        "model.eval()\n",
        "c, s = 0, 0\n",
        "pBar = tqdm(dl_te)\n",
        "for data in pBar:\n",
        "    x, y, = data[0].to(device), data[1].to(device)\n",
        "    p = model(x)\n",
        "    loss = criterion(p, y)\n",
        "    s = ((s*c)+(float(loss)*len(p)))/(c+len(p))\n",
        "    c += len(p)\n",
        "    pBar.set_description('Test: '+str(round(float(s),3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctCRZ-ZNSToN"
      },
      "source": [
        "model.eval()\n",
        "y_pred, y_true = [], []\n",
        "pBar = tqdm(dl_te)\n",
        "for data in pBar:\n",
        "    x, y = data[0].to(device), data[1].to(device)\n",
        "    p = model(x)\n",
        "    y_pred.append(p.cpu().detach().numpy())\n",
        "    y_true.append(y.cpu().detach().numpy())\n",
        "y_pred = np.concatenate(y_pred)\n",
        "y_true = np.concatenate(y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLoFSBIGSTkT"
      },
      "source": [
        "(y_true == y_pred.argmax(axis=1)).mean()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}